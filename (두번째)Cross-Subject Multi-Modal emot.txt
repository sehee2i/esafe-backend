(두번째)Cross-Subject Multi-Modal emotion recognition framework (CSMM)[13]은 EEG 및 시선 움직임 신호를 입력으로 사용하여, 피험자 간 분포 차이와 모달리티 간 이질성을 동시에 해결하기 위한 cross-subject 정렬 기반의 멀티모달 감정인식 프레임워크이다. 먼저, Self-paced Adversarial Domain Adaptation 네트워크를 통해 각 피험자로부터 추출된 특징을 정렬하고, 이후 정렬된 각 모달리티의 임베딩은 self-attention과 cross-attention 모듈을 통해 각 모달 내의 시계열 데이터 정렬 및 각 모달 간의 상호작용을 학습하여 통합적인 표현을 추출한다. 이 과정에서 Modal Matching Loss와 Contrastive Loss를 사용하여 두 모달 간 의미 정합성을 강화하였고, 최종적으로 cross-attention 기반 분류기를 통해 감정 클래스를 예측한다. 이와 같은 구조는 교차 피험자 설정에서의 일반화 성능을 향상시키는 데 초점을 둔다.


(첫번째)Cross-Subject Multi-Modal emotion recognition framework (CSMM)[13]은 EEG 및 시선 움직임 신호를 입력으로 사용하여, 개인 간 분포 차이와 모달리티 이질성을 동시에 해결하는 cross-subject 정렬 기반의 멀티모달 감정인식 프레임워크이다. Self-paced Adversarial Domain Adaptation 네트워크를 통해 도메인 불변 특징을 정렬하며, 이후 self-attention과 cross-attention을 활용하여 intra-/inter-modal 정서 정보를 추출한다. Modal Matching Loss와 Contrastive Loss를 통해 두 모달 간 의미 정합성을 강화하고, 최종적으로 cross-attention 기반 분류기를 통해 감정을 예측한다.



(최종)Cross-Subject Multi-Modal emotion recognition framework (CSMM)[13]은 EEG 및 시선 움직임 신호를 입력으로 사용하여, 피험자 간 분포 차이와 모달리티 간 이질성을 동시에 해결하기 위한 cross-subject 정렬 기반의 멀티모달 감정인식 프레임워크이다. 먼저 모델 아키텍쳐인 그림 1과 같이, Self-paced Adversarial Domain Adapt ation 네트워크를 통해 각 피험자로부터 추출된 특징을 정렬하고, 이후, 정렬된 각 모달리티의 임베딩은 Self-Attention과 Cross-Attention 모듈을 통해 각 모달 내의 시계열 데이터 정렬 및 각 모달 간의 상호작용을 학습하여 통합적인 표현을 추출한다. 이 과정에서 Modal Matching Loss와 Contrastive Loss를 사용하여 두 모달 간 의미 정합성을 강화하였고, 마지막으로, 통합된 표현은 Cross-Attention 기반 분류기를 통해 감정 클래스를 예측되며, 이와 같은 구조는 교차 피험자 일반화 성능을 향상시키는 데 중점을 둔다. 

