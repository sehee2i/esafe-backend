MAHNOB-HCI [5]는 감정 인식을 위한 대표적인 멀티모달 데이터셋으로, 실험 참가자들이 감정 유발 영상 (약 40분)을 시청하는 동안 시선, EEG (32채널), ECG, GSR 등 다양한 생체 및 행동 데이터를 수집하였다. 총 30명의 참가자 중 유효성이 검증된 27명의 데이터를 활용하였으며, 자극 영상 시청 후 참가자는 5개 항목에 대해 9점 척도로 자가 평가를 진행한다. 6대의 카메라 (1 컬러, 5 흑백)를 통한 다각도 얼굴 영상과 환경 비디오가 함께 제공되며, Tobii eye tracker 및 전용 소프트웨어 기반 시선 좌표, 고정 지점 등의 정밀 시선 데이터가 포함된다. 실험은 시선 보정(calibration) 절차를 거친 후 수행되며, 다양한 행동 이벤트 라벨도 함께 제공된다.

MAHNOB-HCI [5]는 실험 참가자들이 약 40분간의 감정 유발 영상을 시청하는 동안 시선, EEG (32채널), ECG, GSR 등 다양한 생체 및 행동 데이터가 수집된 감정인식 멀티모달 데이터셋이다. 총 30명의 피험자 중 27명의 유효한 데이터가 제공되며, 각 실험 세션은 15초 프롬포트 영상 및 감정 유발 영상 시청 후 참가자는 5개 항목에 대해 1에서 9점 척도로 자가 평가를 시행하였다. 데이터는 Tobii eye tracker를 통한 시선 좌표, 고정 지점 등을 포함하며, 총 6대의 카메라 (1 컬러, 5 흑백)를 이용한 다각도 얼굴 영상과 전체 환경 비디오가 함께 제공된다. 실험은 시선 보정 (calibration) 후 진행되며, 특정 행동 이벤트 라벨도 함께 주석되어 있다는 특징이 있다.





  SEED-IV [6]는 EEG와 시선 데이터를 동시에 수집한 고품질 멀티모달 감정 데이터셋이다. 15명의 참가자가 3일에 걸쳐 총 72개의 감정 유발 영상 클립을 시청하며, 4가지 감정 (Happy, Sad, Fearful, Neutral)에 대한 EEG (62채널) 및 Eye movement 데이터를 제공한다. 시선 정보는 응시 시간, 도약 지점, 분산 정도 등의 통계와 이벤트 형태로 후처리되어 있으며, 감정 자극에 대한 평가는 SAM 및 VAS 척도를 통해 자가 보고 방식으로 수집된다. EEG는 5개 주파수 밴드에서 특성 (feature)을 추출하고, 시선 데이터와의 상호 분석이 가능하도록 정제되어 있다.