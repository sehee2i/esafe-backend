논문 1) "Continuous Emotion Recognition in Videos by Fusing Facial Expression, Head Pose and Eye Gaze” (ICMI 2019, ACM 저널/컨퍼런스)
1. 시선 특징 또는 시선에 관한 데이터가 포함된 감정인식 데이터셋
- RECOLA라는 멀티모달 감정인식 데이터셋을 사용
- "비디오, 오디오, 생체신호(ECG,EDA)"포함
2. 시선 특징을 추출해서 사용할 수 있는 감정인식 데이터셋
- 비디오 얼굴에서 시선, 머리자세를 OpenFace 2.0으로 추출하여 사용(추출해서 사용)
- 얼굴에 정면이 잘 노출되어 고정률이 높고, 시선 추출 안정적으로 가능
3. 영상에서 시선 특징을 추출하여 사용한 감정인식 모델 논문
- 모델 이름: FER-P&G-Net
- 핵심: 시선+머리자세를 기반으로 시선 기반 attention mechanism(사람이 어느 쪽을 얼마나 바라보는지를 바탕으로, 어떤 프레임이 중요한지 모델이 스스로 학습하도록 설계.)을 적용하여, 감정 인식의 중요한 프레임에 더 집중, 시선+머리 자세정보를 "추가적 피처로 활용하여 facial features"보완함
- 방법론: 얼굴 이미지에서 CNN + Temporal CNN(TCN) → 시선/머리 정보로 attention + 보조 피처 통합
- 사용 도구: OpenFace 2.0 (eye gaze & head pose 추출), ResNet, TCN, 1D-CNN
- 결과: 기존 모델 대비 **Valence 0.686 / Arousal 0.603 (CCC 기준)**로 우수한 성능
- Ablation Study: 모델에서 일부 구성요소(feature, 모듈, layer 등)를 제거하거나 단독으로 써보면서 그 요소가 성능에 얼마나 기여하는지를 분석하는 실험

-------------
사람의 감정을 판단하기 위해서 안면 영상에서 다양한 특징을 분석할 수 있는 AI 기반 생체 신호 감지 기술을 개발 
-  얼굴 표정과 더불어 눈 깜빡임 빈도, 동공의 움직임 속도, 시선의 방향 등 다양한 정보를 추출해 이를 신호화하고, 분석, 영상을 통한 비접촉식 심박수 추출 기술과의 융합을 통해 신체의 내적 생체 신호와 얼굴로 표출되는 외적 생체 신호를 종합적으로 활용하는 고성능 감정 판단 기술 설계도 진행 중
(이런 기술을 토대로 범죄 수사에서 용의자의 신문뿐만 아니라 출입국 심사 시 밀반입을 시도하려는 대상자를 선별하거나 보이스피싱 피해자 감지 및 예방 등 다양한 방식으로 활용 가능하다. 한 발 더 나아가 대상자의 감정 상태에 적합한 맞춤형 서비스 제공이나 스마트 홈 등 다양한 플랫폼에서도 활용할 수 있는 매력적인 기술)

